"""
é¢„æµ‹è„šæœ¬
åŠŸèƒ½ï¼šä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æ–°åŒ–åˆç‰©è¿›è¡ŒTHRBæ´»æ€§é¢„æµ‹
æ”¯æŒ6ç§æ¨¡å‹ï¼šRandom Forest, XGBoost, Gradient Boosting, SVM, Logistic Regression, THRB GNN
"""

import numpy as np
import pandas as pd
import joblib
from rdkit import Chem
from rdkit.Chem import Descriptors, Draw
import os
import warnings
warnings.filterwarnings('ignore')

from feature_extraction import MolecularFeatureExtractor

# å°è¯•å¯¼å…¥GNNæ¨¡å‹
try:
    from model_gnn import GNNClassifier
    GNN_AVAILABLE = True
except ImportError:
    GNN_AVAILABLE = False
    print("æç¤º: GNNæ¨¡å‹ä¾èµ–æœªå®‰è£…ï¼ŒGNNé¢„æµ‹åŠŸèƒ½ä¸å¯ç”¨")


class THRBPredictor:
    """THRBæ´»æ€§é¢„æµ‹å™¨ï¼ˆæ”¯æŒ6ç§æ¨¡å‹ï¼‰"""
    
    def __init__(self, model_name='best', model_path=None,
                 scaler_path='models/scaler.pkl',
                 fingerprint_type='combined'):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        å‚æ•°:
            model_name: æ¨¡å‹åç§°ï¼Œå¯é€‰å€¼:
                - 'best': æœ€ä½³æ¨¡å‹ï¼ˆé»˜è®¤ï¼‰
                - 'random_forest': éšæœºæ£®æ—
                - 'xgboost': XGBoost
                - 'gradient_boosting': æ¢¯åº¦æå‡
                - 'gradient_boosting': æ”¯æŒå‘é‡æœº
                - 'logistic_regression': é€»è¾‘å›å½’
                - 'gnn' æˆ– 'thrb_gnn': å›¾ç¥ç»ç½‘ç»œ
            model_path: è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¼šè¦†ç›–model_nameï¼‰
            scaler_path: æ ‡å‡†åŒ–å™¨è·¯å¾„
            fingerprint_type: ç‰¹å¾æå–ç±»å‹
        """
        self.model_name = model_name
        self.fingerprint_type = fingerprint_type
        self.scaler_path = scaler_path
        
        # æ¨¡å‹æ˜ å°„
        self.model_files = {
            'best': 'models/best_model.pkl',
            'random_forest': 'models/model_random_forest.pkl',
            'xgboost': 'models/model_xgboost.pkl',
            'gradient_boosting': 'models/model_gradient_boosting.pkl',
            'svm': 'models/model_svm.pkl',
            'logistic_regression': 'models/model_logistic_regression.pkl',
            'gnn': 'models/model_thrb_gnn.pkl',
            'thrb_gnn': 'models/model_thrb_gnn.pkl'
        }
        
        # ç¡®å®šæ¨¡å‹è·¯å¾„
        if model_path:
            self.model_path = model_path
        else:
            self.model_path = self.model_files.get(model_name.lower(), 'models/best_model.pkl')
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯GNNæ¨¡å‹
        self.is_gnn = 'gnn' in model_name.lower() or 'gnn' in self.model_path.lower()
        
        # åŠ è½½æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨
        self.model = None
        self.scaler = None
        self.feature_extractor = None
        
        self._load_model()
        
    def _load_model(self):
        """åŠ è½½æ¨¡å‹å’Œç›¸å…³ç»„ä»¶"""
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
        
        # GNNæ¨¡å‹æ£€æŸ¥
        if self.is_gnn:
            if not GNN_AVAILABLE:
                raise ImportError("GNNæ¨¡å‹éœ€è¦PyTorchå’ŒPyTorch Geometricï¼Œè¯·å…ˆå®‰è£…ï¼š\n"
                                "pip install torch torchvision torchaudio\n"
                                "pip install torch-geometric")
            print("æ­£åœ¨åŠ è½½GNNæ¨¡å‹...")
        else:
            if not os.path.exists(self.scaler_path):
                raise FileNotFoundError(f"æ ‡å‡†åŒ–å™¨æ–‡ä»¶ä¸å­˜åœ¨: {self.scaler_path}")
            print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_name}...")
        
        self.model = joblib.load(self.model_path)
        
        # ä¼ ç»ŸMLæ¨¡å‹éœ€è¦scalerå’Œç‰¹å¾æå–å™¨
        if not self.is_gnn:
            self.scaler = joblib.load(self.scaler_path)
            
            # åˆå§‹åŒ–ç‰¹å¾æå–å™¨
            self.feature_extractor = MolecularFeatureExtractor(
                fingerprint_type=self.fingerprint_type,
                radius=2,
                n_bits=2048
            )
        
        print("æ¨¡å‹åŠ è½½å®Œæˆï¼")
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        if self.is_gnn:
            print("  æ¨¡å‹ç±»å‹: å›¾ç¥ç»ç½‘ç»œ (GNN)")
            print("  ç‰¹ç‚¹: ç›´æ¥ä»åˆ†å­å›¾ç»“æ„å­¦ä¹ ")
        else:
            print(f"  æ¨¡å‹ç±»å‹: {self.model_name}")
            print(f"  ç‰¹å¾ç±»å‹: {self.fingerprint_type}")
    
    def validate_smiles(self, smiles):
        """éªŒè¯SMILESæœ‰æ•ˆæ€§"""
        mol = Chem.MolFromSmiles(smiles)
        return mol is not None
    
    def predict_single(self, smiles, return_proba=True):
        """
        é¢„æµ‹å•ä¸ªåŒ–åˆç‰©çš„æ´»æ€§
        
        å‚æ•°:
            smiles: SMILESå­—ç¬¦ä¸²
            return_proba: æ˜¯å¦è¿”å›é¢„æµ‹æ¦‚ç‡
            
        è¿”å›:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        # éªŒè¯SMILES
        if not self.validate_smiles(smiles):
            return {
                'smiles': smiles,
                'valid': False,
                'error': 'Invalid SMILES',
                'model': self.model_name
            }
        
        # GNNæ¨¡å‹ä½¿ç”¨ä¸åŒçš„é¢„æµ‹æ–¹å¼
        if self.is_gnn:
            # GNNéœ€è¦SMILESï¼Œä¸éœ€è¦ç‰¹å¾æå–
            X_dummy = np.zeros((1, 2058))  # Dummyç‰¹å¾çŸ©é˜µ
            smiles_list = [smiles]
            
            # é¢„æµ‹
            prediction = self.model.predict(X_dummy, smiles_list)[0]
            
            result = {
                'smiles': smiles,
                'valid': True,
                'prediction': int(prediction),
                'model': self.model_name
            }
            
            if return_proba:
                proba = self.model.predict_proba(X_dummy, smiles_list)[0]
                result['probability_active'] = float(proba[1])
                result['confidence'] = float(max(proba))
        else:
            # ä¼ ç»ŸMLæ¨¡å‹ï¼šæå–ç‰¹å¾
            features = self.feature_extractor.extract_features_from_smiles(smiles)
            features = features.reshape(1, -1)
            
            # æ ‡å‡†åŒ–
            features = self.scaler.transform(features)
            
            # é¢„æµ‹
            prediction = self.model.predict(features)[0]
            
            result = {
                'smiles': smiles,
                'valid': True,
                'prediction': int(prediction),
                'model': self.model_name
            }
            
            if return_proba:
                proba = self.model.predict_proba(features)[0]
                result['probability_active'] = float(proba[1])
                result['confidence'] = float(max(proba))
        
        # è®¡ç®—åˆ†å­æ€§è´¨
        mol = Chem.MolFromSmiles(smiles)
        result['molecular_weight'] = Descriptors.MolWt(mol)
        result['logp'] = Descriptors.MolLogP(mol)
        result['h_bond_donors'] = Descriptors.NumHDonors(mol)
        result['h_bond_acceptors'] = Descriptors.NumHAcceptors(mol)
        
        return result
    
    def predict_batch(self, smiles_list, return_proba=True):
        """
        æ‰¹é‡é¢„æµ‹åŒ–åˆç‰©æ´»æ€§
        
        å‚æ•°:
            smiles_list: SMILESåˆ—è¡¨
            return_proba: æ˜¯å¦è¿”å›é¢„æµ‹æ¦‚ç‡
            
        è¿”å›:
            é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        print(f"æ­£åœ¨ä½¿ç”¨ {self.model_name} æ¨¡å‹é¢„æµ‹ {len(smiles_list)} ä¸ªåŒ–åˆç‰©...")
        
        # GNNæ¨¡å‹å¯ä»¥æ‰¹é‡é¢„æµ‹ï¼ˆæ›´é«˜æ•ˆï¼‰
        if self.is_gnn:
            results = []
            valid_smiles = []
            valid_indices = []
            
            # éªŒè¯SMILES
            for idx, smiles in enumerate(smiles_list):
                if self.validate_smiles(smiles):
                    valid_smiles.append(smiles)
                    valid_indices.append(idx)
                else:
                    results.append({
                        'smiles': smiles,
                        'valid': False,
                        'error': 'Invalid SMILES',
                        'model': self.model_name
                    })
            
            # æ‰¹é‡é¢„æµ‹æœ‰æ•ˆçš„SMILES
            if valid_smiles:
                print(f"  æœ‰æ•ˆSMILES: {len(valid_smiles)}/{len(smiles_list)}")
                X_dummy = np.zeros((len(valid_smiles), 2058))
                predictions = self.model.predict(X_dummy, valid_smiles)
                
                if return_proba:
                    probabilities = self.model.predict_proba(X_dummy, valid_smiles)
                
                # æ•´ç†ç»“æœ
                valid_results = []
                for i, smiles in enumerate(valid_smiles):
                    mol = Chem.MolFromSmiles(smiles)
                    result = {
                        'smiles': smiles,
                        'valid': True,
                        'prediction': int(predictions[i]),
                        'model': self.model_name,
                        'molecular_weight': Descriptors.MolWt(mol),
                        'logp': Descriptors.MolLogP(mol),
                        'h_bond_donors': Descriptors.NumHDonors(mol),
                        'h_bond_acceptors': Descriptors.NumHAcceptors(mol)
                    }
                    
                    if return_proba:
                        result['probability_active'] = float(probabilities[i][1])
                        result['confidence'] = float(max(probabilities[i]))
                    
                    valid_results.append(result)
                
                # åˆå¹¶ç»“æœï¼ˆä¿æŒåŸå§‹é¡ºåºï¼‰
                final_results = []
                valid_idx = 0
                invalid_idx = 0
                for idx in range(len(smiles_list)):
                    if idx in valid_indices:
                        final_results.append(valid_results[valid_idx])
                        valid_idx += 1
                    else:
                        final_results.append(results[invalid_idx])
                        invalid_idx += 1
                
                results = final_results
        else:
            # ä¼ ç»ŸMLæ¨¡å‹ï¼šé€ä¸ªé¢„æµ‹
            results = []
            for idx, smiles in enumerate(smiles_list):
                if (idx + 1) % 100 == 0:
                    print(f"  è¿›åº¦: {idx + 1}/{len(smiles_list)}")
                
                result = self.predict_single(smiles, return_proba=return_proba)
                results.append(result)
        
        print("é¢„æµ‹å®Œæˆï¼")
        return results
    
    def predict_from_file(self, input_file, smiles_column='smiles', 
                         output_file='predictions.csv'):
        """
        ä»æ–‡ä»¶è¯»å–SMILESå¹¶é¢„æµ‹
        
        å‚æ•°:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆCSVæ ¼å¼ï¼‰
            smiles_column: SMILESåˆ—å
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # è¯»å–è¾“å…¥æ–‡ä»¶
        print(f"æ­£åœ¨è¯»å–æ–‡ä»¶: {input_file}")
        df = pd.read_csv(input_file)
        
        if smiles_column not in df.columns:
            raise ValueError(f"åˆ— '{smiles_column}' ä¸å­˜åœ¨äºè¾“å…¥æ–‡ä»¶ä¸­")
        
        print(f"æ–‡ä»¶åŒ…å« {len(df)} ä¸ªåŒ–åˆç‰©")
        
        # æ‰¹é‡é¢„æµ‹
        smiles_list = df[smiles_column].tolist()
        results = self.predict_batch(smiles_list)
        
        # è½¬æ¢ä¸ºDataFrame
        results_df = pd.DataFrame(results)
        
        # åˆå¹¶åŸå§‹æ•°æ®
        output_df = pd.concat([df, results_df.drop('smiles', axis=1)], axis=1)
        
        # æŒ‰æ´»æ€§æ¦‚ç‡æ’åºï¼ˆé™åºï¼‰
        if 'probability_active' in output_df.columns:
            output_df = output_df.sort_values('probability_active', ascending=False)
            print("ç»“æœå·²æŒ‰æ´»æ€§æ¦‚ç‡ä»é«˜åˆ°ä½æ’åº")
        
        # å¯¹æ•°å€¼åˆ—ä¿ç•™ä¸¤ä½å°æ•°
        numeric_columns = ['probability_active', 'confidence', 
                          'molecular_weight', 'logp', 'h_bond_donors', 'h_bond_acceptors']
        for col in numeric_columns:
            if col in output_df.columns:
                output_df[col] = output_df[col].round(2)
        
        # ä¿å­˜ç»“æœ
        output_df.to_csv(output_file, index=False)
        print(f"é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        return output_df
    
    def visualize_molecule(self, smiles, output_path=None):
        """
        å¯è§†åŒ–åˆ†å­ç»“æ„
        
        å‚æ•°:
            smiles: SMILESå­—ç¬¦ä¸²
            output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        mol = Chem.MolFromSmiles(smiles)
        
        if mol is None:
            print(f"æ— æ•ˆçš„SMILES: {smiles}")
            return None
        
        img = Draw.MolToImage(mol, size=(400, 400))
        
        if output_path:
            img.save(output_path)
            print(f"åˆ†å­ç»“æ„å›¾å·²ä¿å­˜åˆ°: {output_path}")
        
        return img


def compare_models(smiles):
    """æ¯”è¾ƒæ‰€æœ‰å¯ç”¨æ¨¡å‹çš„é¢„æµ‹ç»“æœ"""
    print("\n" + "="*80)
    print("å¤šæ¨¡å‹é¢„æµ‹å¯¹æ¯”")
    print("="*80)
    print(f"SMILES: {smiles}\n")
    
    # æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
    models_to_test = [
        ('best', 'æœ€ä½³æ¨¡å‹'),
        ('random_forest', 'Random Forest'),
        ('xgboost', 'XGBoost'),
        ('gradient_boosting', 'Gradient Boosting'),
        ('svm', 'SVM'),
        ('logistic_regression', 'Logistic Regression'),
        ('gnn', 'THRB GNN')
    ]
    
    results = []
    
    for model_name, display_name in models_to_test:
        try:
            predictor = THRBPredictor(model_name=model_name, fingerprint_type='combined')
            result = predictor.predict_single(smiles)
            results.append({
                'æ¨¡å‹': display_name,
                'æ´»æ€§æ¦‚ç‡': f"{result['probability_active']:.2f}",
                'ç½®ä¿¡åº¦': f"{result['confidence']:.2f}"
            })
            print(f"âœ… {display_name}: æ´»æ€§æ¦‚ç‡={result['probability_active']:.2f}")
        except FileNotFoundError:
            print(f"âš ï¸  {display_name}: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
        except Exception as e:
            print(f"âŒ {display_name}: {str(e)}")
    
    if results:
        print("\næ¨¡å‹é¢„æµ‹æ±‡æ€»:")
        df = pd.DataFrame(results)
        print(df.to_string(index=False))
        return df
    return None


def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºé¢„æµ‹åŠŸèƒ½"""
    
    print("="*80)
    print("THRB æ´»æ€§é¢„æµ‹ç³»ç»Ÿ - æ”¯æŒ6ç§æ¨¡å‹")
    print("="*80)
    
    # ç¤ºä¾‹1ï¼šä½¿ç”¨æœ€ä½³æ¨¡å‹é¢„æµ‹
    print("\nç¤ºä¾‹ 1: ä½¿ç”¨æœ€ä½³æ¨¡å‹é¢„æµ‹å•ä¸ªåŒ–åˆç‰©")
    print("-" * 80)
    
    # åˆ›å»ºé¢„æµ‹å™¨ï¼ˆä½¿ç”¨æœ€ä½³æ¨¡å‹ï¼‰
    predictor = THRBPredictor(model_name='best', fingerprint_type='combined')
    
    # T3ï¼ˆä¸‰ç¢˜ç”²çŠ¶è…ºåŸæ°¨é…¸ï¼‰- å·²çŸ¥THRBæ¿€åŠ¨å‰‚
    smiles_t3 = "N[C@@H](Cc1cc(I)c(Oc2cc(I)c(O)c(I)c2)c(I)c1)C(=O)O"
    
    result = predictor.predict_single(smiles_t3)
    
    print(f"\nSMILES: {result['smiles'][:50]}...")
    print(f"ä½¿ç”¨æ¨¡å‹: {result['model']}")
    print(f"æ´»æ€§æ¦‚ç‡: {result['probability_active']:.2f}")
    print(f"ç½®ä¿¡åº¦: {result['confidence']:.2f}")
    print(f"åˆ†å­é‡: {result['molecular_weight']:.2f}")
    print(f"LogP: {result['logp']:.2f}")
    
    # ç¤ºä¾‹2ï¼šä½¿ç”¨GNNæ¨¡å‹
    if GNN_AVAILABLE and os.path.exists('models/model_thrb_gnn.pkl'):
        print("\nç¤ºä¾‹ 2: ä½¿ç”¨GNNæ¨¡å‹é¢„æµ‹")
        print("-" * 80)
        
        gnn_predictor = THRBPredictor(model_name='gnn')
        gnn_result = gnn_predictor.predict_single(smiles_t3)
        
        print(f"\nä½¿ç”¨æ¨¡å‹: GNN (å›¾ç¥ç»ç½‘ç»œ)")
        print(f"æ´»æ€§æ¦‚ç‡: {gnn_result['probability_active']:.2f}")
        print(f"ç½®ä¿¡åº¦: {gnn_result['confidence']:.2f}")
    
    # ç¤ºä¾‹3ï¼šæ‰¹é‡é¢„æµ‹
    print("\nç¤ºä¾‹ 3: æ‰¹é‡é¢„æµ‹å¤šä¸ªåŒ–åˆç‰©")
    print("-" * 80)
    
    # å¤šä¸ªæµ‹è¯•åŒ–åˆç‰©
    test_compounds = [
        "CCOc1ccc(C2NC(=O)NC2=O)cc1",  # æµ‹è¯•åŒ–åˆç‰©1
        "Cc1ccc(O)cc1",  # å¯¹ç”²é…š
        "c1ccc(cc1)c2ccccc2",  # è”è‹¯
        "CC(=O)Oc1ccccc1C(=O)O",  # é˜¿å¸åŒ¹æ—
    ]
    
    results = predictor.predict_batch(test_compounds)
    
    # æ˜¾ç¤ºç»“æœ
    results_df = pd.DataFrame(results)
    print("\né¢„æµ‹ç»“æœ:")
    display_cols = ['smiles', 'model', 'probability_active', 'confidence']
    print(results_df[display_cols].to_string(index=False))
    
    # ä¿å­˜ç»“æœ
    results_df.to_csv('example_predictions.csv', index=False)
    print("\nâœ… ç»“æœå·²ä¿å­˜åˆ°: example_predictions.csv")
    
    # ç¤ºä¾‹4ï¼šå¤šæ¨¡å‹å¯¹æ¯”
    print("\nç¤ºä¾‹ 4: å¤šæ¨¡å‹é¢„æµ‹å¯¹æ¯”")
    print("-" * 80)
    test_smiles = "Cc1ccc(O)cc1"
    compare_models(test_smiles)
    
    # ä½¿ç”¨è¯´æ˜
    print("\n" + "="*80)
    print("ğŸ’¡ ä½¿ç”¨è¯´æ˜")
    print("="*80)
    print("\n1. é€‰æ‹©ç‰¹å®šæ¨¡å‹é¢„æµ‹:")
    print("   predictor = THRBPredictor(model_name='xgboost')  # æˆ– 'gnn', 'random_forest' ç­‰")
    print("   result = predictor.predict_single('YOUR_SMILES')")
    
    print("\n2. æ‰¹é‡é¢„æµ‹:")
    print("   results = predictor.predict_batch(['SMILES1', 'SMILES2', ...])")
    
    print("\n3. ä»æ–‡ä»¶é¢„æµ‹:")
    print("   predictor.predict_from_file('input.csv', output_file='output.csv')")
    
    print("\n4. å¯ç”¨çš„æ¨¡å‹:")
    print("   - 'best': æœ€ä½³æ¨¡å‹ï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰")
    print("   - 'random_forest': éšæœºæ£®æ—")
    print("   - 'xgboost': XGBoost")
    print("   - 'gradient_boosting': æ¢¯åº¦æå‡")
    print("   - 'svm': æ”¯æŒå‘é‡æœº")
    print("   - 'logistic_regression': é€»è¾‘å›å½’")
    print("   - 'gnn': å›¾ç¥ç»ç½‘ç»œ â­")
    
    print("\n" + "="*80)


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='THRBæ´»æ€§é¢„æµ‹å·¥å…·ï¼ˆæ”¯æŒ6ç§æ¨¡å‹ï¼‰')
    parser.add_argument('--model', type=str, default='best',
                       choices=['best', 'random_forest', 'xgboost', 'gradient_boosting', 
                               'svm', 'logistic_regression', 'gnn', 'thrb_gnn'],
                       help='é€‰æ‹©é¢„æµ‹æ¨¡å‹ï¼ˆé»˜è®¤: bestï¼‰')
    parser.add_argument('--smiles', type=str, help='å•ä¸ªSMILESå­—ç¬¦ä¸²')
    parser.add_argument('--input', type=str, help='è¾“å…¥CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, default='predictions.csv', 
                       help='è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: predictions.csvï¼‰')
    parser.add_argument('--smiles-column', type=str, default='smiles',
                       help='CSVæ–‡ä»¶ä¸­çš„SMILESåˆ—åï¼ˆé»˜è®¤: smilesï¼‰')
    parser.add_argument('--compare', action='store_true',
                       help='æ¯”è¾ƒæ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹ç»“æœ')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ¨¡å‹ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists('models'):
        print("âŒ é”™è¯¯ï¼šmodelsç›®å½•ä¸å­˜åœ¨ï¼")
        print("\nè¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼š")
        print("  python data_preprocessing.py")
        print("  python feature_extraction.py")
        print("  python model_training.py")
        exit(1)
    
    # å‘½ä»¤è¡Œæ¨¡å¼
    if args.smiles or args.input or args.compare:
        try:
            predictor = THRBPredictor(model_name=args.model, fingerprint_type='combined')
            
            if args.compare and args.smiles:
                # æ¯”è¾ƒæ¨¡å¼
                compare_models(args.smiles)
            elif args.smiles:
                # å•ä¸ªSMILESé¢„æµ‹
                result = predictor.predict_single(args.smiles)
                print(f"\né¢„æµ‹ç»“æœ:")
                print(f"  SMILES: {result['smiles']}")
                print(f"  æ¨¡å‹: {result['model']}")
                print(f"  æ´»æ€§æ¦‚ç‡: {result['probability_active']:.2f}")
                print(f"  ç½®ä¿¡åº¦: {result['confidence']:.2f}")
            elif args.input:
                # æ–‡ä»¶æ‰¹é‡é¢„æµ‹
                predictor.predict_from_file(
                    input_file=args.input,
                    smiles_column=args.smiles_column,
                    output_file=args.output
                )
            
        except FileNotFoundError as e:
            print(f"âŒ é”™è¯¯: {e}")
            print("\næç¤º: ç¡®ä¿å·²è¿è¡Œå®Œæ•´çš„æ¨¡å‹è®­ç»ƒæµç¨‹")
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
    else:
        # æ¼”ç¤ºæ¨¡å¼
        if not os.path.exists('models/best_model.pkl'):
            print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼")
            print("\nè¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼š")
            print("  python data_preprocessing.py")
            print("  python feature_extraction.py")
            print("  python model_training.py")
        else:
            main()

