# THRB äºŒåˆ†ç±»æ¨¡å‹é¡¹ç›®

è¿™æ˜¯ä¸€ä¸ªç”¨äºé¢„æµ‹åŒ–åˆç‰©å¯¹ç”²çŠ¶è…ºæ¿€ç´ å—ä½“Î²ï¼ˆTHRBï¼‰æ´»æ€§çš„æœºå™¨å­¦ä¹ é¡¹ç›®ã€‚é¡¹ç›®åŸºäºChEMBLæ•°æ®åº“ï¼Œä½¿ç”¨**6ç§ç®—æ³•**ï¼ˆåŒ…æ‹¬ä¼ ç»Ÿæœºå™¨å­¦ä¹ å’Œå›¾ç¥ç»ç½‘ç»œGNNï¼‰æ„å»ºäºŒåˆ†ç±»é¢„æµ‹æ¨¡å‹ã€‚

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

---

## ğŸ“‹ é¡¹ç›®ç®€ä»‹

### æ ¸å¿ƒåŠŸèƒ½
- ğŸ¯ **ç›®æ ‡**: é¢„æµ‹æœªçŸ¥åŒ–åˆç‰©å¯¹THRBçš„æ´»æ€§ï¼ˆæ´»æ€§/éæ´»æ€§ï¼‰
- ğŸ“Š **æ•°æ®é›†**: ~5400æ¡THRBç›¸å…³åŒ–åˆç‰©æ•°æ®ï¼ˆä»81000+æ¡è®°å½•ä¸­ç­›é€‰ï¼‰
- ğŸ¤– **æ¨¡å‹**: 6ç§ç®—æ³•ï¼ˆ5ä¸ªä¼ ç»ŸML + 1ä¸ªGNNï¼‰
- ğŸ“ˆ **æ€§èƒ½**: ROC AUC 0.75-0.85+
- ğŸ”¬ **æ´»æ€§å®šä¹‰**: pchembl_value â‰¥ **6.0** ä¸ºæ´»æ€§åŒ–åˆç‰©

### æ¨¡å‹åˆ—è¡¨

| # | æ¨¡å‹åç§° | ç±»å‹ | ç‰¹ç‚¹ | é¢„æœŸæ€§èƒ½ |
|---|---------|------|------|---------|
| 1 | Random Forest | ä¼ ç»ŸML | ç¨³å®šã€å¯è§£é‡Š | AUC 0.76 |
| 2 | XGBoost | ä¼ ç»ŸML | é«˜æ€§èƒ½ã€å¿«é€Ÿ | AUC 0.76 |
| 3 | Gradient Boosting | ä¼ ç»ŸML | é›†æˆå­¦ä¹  | AUC 0.75 |
| 4 | SVM | ä¼ ç»ŸML | æ ¸æ–¹æ³• | AUC 0.74 |
| 5 | Logistic Regression | ä¼ ç»ŸML | ç®€å•å¿«é€Ÿ | AUC 0.68 |
| 6 | **THRB GNN** â­ | **æ·±åº¦å­¦ä¹ ** | **ç›´æ¥å­¦ä¹ åˆ†å­å›¾ç»“æ„** | **AUC 0.78-0.85** |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ¡ˆA: ä»…ä½¿ç”¨ä¼ ç»ŸMLæ¨¡å‹ï¼ˆæ¨èåˆæ¬¡ä½¿ç”¨ï¼‰

```bash
# 1. å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# 2. ä¸€é”®è¿è¡Œå®Œæ•´æµç¨‹
python main.py full

# 3. æŸ¥çœ‹ç»“æœ
# - models/model_comparison.csv
# - results/*.png
```

### æ–¹æ¡ˆB: ä½¿ç”¨å…¨éƒ¨6ä¸ªæ¨¡å‹ï¼ˆåŒ…æ‹¬GNNï¼‰

```bash
# 1. å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# 2. å®‰è£…GNNä¾èµ–
pip install torch torchvision torchaudio
pip install torch-geometric

# 3. æµ‹è¯•GNNç¯å¢ƒ
python test_gnn.py

# 4. è®­ç»ƒæ‰€æœ‰æ¨¡å‹ï¼ˆåŒ…æ‹¬GNNï¼‰
python model_training.py

# 5. è¯„ä¼°å’Œå¯è§†åŒ–
python model_evaluation.py
```

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
THRBER/
â”‚
â”œâ”€â”€ ğŸ“„ æ ¸å¿ƒè„šæœ¬
â”‚   â”œâ”€â”€ main.py                     # ä¸»ç¨‹åºå…¥å£ï¼ˆä¼ ç»ŸMLæµç¨‹ï¼‰
â”‚   â”œâ”€â”€ data_preprocessing.py       # æ•°æ®é¢„å¤„ç†
â”‚   â”œâ”€â”€ feature_extraction.py       # ç‰¹å¾æå–
â”‚   â”œâ”€â”€ model_training.py           # æ¨¡å‹è®­ç»ƒï¼ˆ6ä¸ªæ¨¡å‹ï¼‰
â”‚   â”œâ”€â”€ model_evaluation.py         # æ¨¡å‹è¯„ä¼°å’Œå¯è§†åŒ–
â”‚   â”œâ”€â”€ model_gnn.py               # GNNæ¨¡å‹å®ç° â­
â”‚   â”œâ”€â”€ predict.py                  # é¢„æµ‹æ¨¡å—
â”‚   â””â”€â”€ test_gnn.py                # GNNç¯å¢ƒæµ‹è¯• â­
â”‚
â”œâ”€â”€ ğŸ“Š æ•°æ®æ–‡ä»¶
â”‚   â”œâ”€â”€ nr_activities.csv           # åŸå§‹æ•°æ®é›†ï¼ˆ81000+æ¡ï¼‰
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ thrb_processed.csv      # å¤„ç†åæ•°æ®ï¼ˆ~5400æ¡ï¼‰
â”‚   â”‚   â”œâ”€â”€ data_statistics.txt     # æ•°æ®ç»Ÿè®¡
â”‚   â”‚   â”œâ”€â”€ features_combined.npz   # ç»„åˆç‰¹å¾ï¼ˆ2058ç»´ï¼‰
â”‚   â”‚   â””â”€â”€ features_morgan.npz     # MorganæŒ‡çº¹ï¼ˆ2048ç»´ï¼‰
â”‚
â”œâ”€â”€ ğŸ¤– æ¨¡å‹æ–‡ä»¶
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ best_model.pkl          # æœ€ä½³æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ scaler.pkl              # ç‰¹å¾æ ‡å‡†åŒ–å™¨
â”‚   â”‚   â”œâ”€â”€ model_random_forest.pkl
â”‚   â”‚   â”œâ”€â”€ model_xgboost.pkl
â”‚   â”‚   â”œâ”€â”€ model_gradient_boosting.pkl
â”‚   â”‚   â”œâ”€â”€ model_svm.pkl
â”‚   â”‚   â”œâ”€â”€ model_logistic_regression.pkl
â”‚   â”‚   â”œâ”€â”€ model_thrb_gnn.pkl     # GNNæ¨¡å‹ â­
â”‚   â”‚   â”œâ”€â”€ smiles_test.npy        # æµ‹è¯•é›†SMILES â­
â”‚   â”‚   â”œâ”€â”€ model_comparison.csv    # æ€§èƒ½å¯¹æ¯”
â”‚   â”‚   â””â”€â”€ evaluation_report.txt   # è¯¦ç»†æŠ¥å‘Š
â”‚
â”œâ”€â”€ ğŸ“ˆ ç»“æœæ–‡ä»¶
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ roc_curves.png          # ROCæ›²çº¿ï¼ˆ6æ¡ï¼‰
â”‚       â”œâ”€â”€ precision_recall_curves.png
â”‚       â”œâ”€â”€ confusion_matrices.png  # æ··æ·†çŸ©é˜µï¼ˆ6ä¸ªï¼‰
â”‚       â”œâ”€â”€ model_comparison.png
â”‚       â”œâ”€â”€ feature_importance.png
â”‚       â”œâ”€â”€ prediction_distributions.png
â”‚       â””â”€â”€ classification_reports.txt
â”‚
â””â”€â”€ ğŸ“š æ–‡æ¡£å’Œé…ç½®
    â”œâ”€â”€ README.md                   # æœ¬æ–‡æ¡£
    â”œâ”€â”€ requirements.txt            # Pythonä¾èµ–
    â”œâ”€â”€ install_gnn_simple.bat     # GNNå®‰è£…è„šæœ¬ï¼ˆWindowsï¼‰
    â””â”€â”€ example_compounds.csv      # ç¤ºä¾‹åŒ–åˆç‰©
```

---

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚

### 1. æ•°æ®é¢„å¤„ç†

**æµç¨‹**:
```python
åŸå§‹æ•°æ®ï¼ˆ81305æ¡ï¼‰
  â†“ ç­›é€‰THRBç›¸å…³
THRBæ•°æ®ï¼ˆ~6600æ¡ï¼‰
  â†“ éªŒè¯SMILESæœ‰æ•ˆæ€§
æœ‰æ•ˆæ•°æ®ï¼ˆ~6500æ¡ï¼‰
  â†“ å»é‡
æœ€ç»ˆæ•°æ®ï¼ˆ5427æ¡ï¼‰
  â†“ äºŒåˆ†ç±»æ ‡æ³¨ï¼ˆpchembl â‰¥ 6.0ï¼‰
æ´»æ€§: 1489 (27.4%) | éæ´»æ€§: 3938 (72.6%)
```

**å…³é”®å‚æ•°**:
- æ´»æ€§é˜ˆå€¼: `pchembl_value >= 6.0`
- æ•°æ®æ¥æº: ChEMBLï¼ˆNR1A2/THRBï¼‰
- å»é‡ä¾æ®: canonical_smiles

### 2. ç‰¹å¾å·¥ç¨‹

#### ä¼ ç»ŸMLç‰¹å¾ï¼ˆ2058ç»´ï¼‰

| ç‰¹å¾ç±»å‹ | ç»´åº¦ | è¯´æ˜ |
|---------|------|------|
| MorganæŒ‡çº¹ | 2048 | ECFPåŠå¾„=2ï¼Œæ•è·å­ç»“æ„ |
| RDKitæè¿°ç¬¦ | 10 | åˆ†å­é‡ã€LogPã€TPSAç­‰ |
| **ç»„åˆç‰¹å¾** | **2058** | **æ¨èä½¿ç”¨** |

**åˆ†å­æè¿°ç¬¦**:
- åˆ†å­é‡ (Molecular Weight)
- LogP (è„‚æ°´åˆ†é…ç³»æ•°)
- TPSA (æ‹“æ‰‘ææ€§è¡¨é¢ç§¯)
- æ°¢é”®ä¾›ä½“/å—ä½“æ•°
- å¯æ—‹è½¬é”®æ•°
- èŠ³é¦™ç¯æ•°
- é¥±å’Œç¯æ•°
- è„‚è‚ªç¯æ•°ç­‰

#### GNNç‰¹å¾ï¼ˆè‡ªåŠ¨å­¦ä¹ ï¼‰

GNNç›´æ¥ä»SMILESå­¦ä¹ åˆ†å­å›¾ç»“æ„ï¼š

```
SMILES â†’ åˆ†å­å›¾
  â†“
èŠ‚ç‚¹ç‰¹å¾ï¼ˆåŸå­ï¼‰:
  - åŸå­åºæ•°ã€åº¦ã€ç”µè·
  - æ°¢åŸå­æ•°ã€èŠ³é¦™æ€§
  - æ˜¯å¦åœ¨ç¯ä¸­ã€åŒ–åˆä»·
  ï¼ˆå…±9ä¸ªç‰¹å¾ï¼‰
  â†“
è¾¹ï¼ˆåŒ–å­¦é”®ï¼‰:
  - å•é”®ã€åŒé”®ã€ä¸‰é”®
  - èŠ³é¦™é”®ç­‰
```

### 3. æ¨¡å‹æ¶æ„

#### ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹

**Random Forest**
```python
n_estimators=200
max_depth=20
min_samples_split=5
class_weight='balanced'  # å¤„ç†ä¸å¹³è¡¡
```

**XGBoost**
```python
n_estimators=200
max_depth=6
learning_rate=0.1
subsample=0.8
scale_pos_weight=2.6  # å¤„ç†ä¸å¹³è¡¡
```

**å¤„ç†ç±»åˆ«ä¸å¹³è¡¡**:
- ä½¿ç”¨SMOTEè¿‡é‡‡æ ·
- ç±»åˆ«æƒé‡è°ƒæ•´
- ä» 3938:1489 â†’ å¹³è¡¡æ•°æ®é›†

#### GNNæ¨¡å‹æ¶æ„ â­

```
è¾“å…¥: SMILESå­—ç¬¦ä¸²
  â†“
åˆ†å­å›¾è½¬æ¢ï¼ˆåŸå­=èŠ‚ç‚¹ï¼ŒåŒ–å­¦é”®=è¾¹ï¼‰
  â†“
å›¾å·ç§¯å±‚1: GCNConv(9 â†’ 128)
  + BatchNorm + ReLU + Dropout(0.3)
  â†“
å›¾å·ç§¯å±‚2: GCNConv(128 â†’ 128)
  + BatchNorm + ReLU + Dropout(0.3)
  â†“
å›¾å·ç§¯å±‚3: GCNConv(128 â†’ 128)
  + BatchNorm + ReLU
  â†“
å…¨å±€æ± åŒ–: Mean Pooling + Max Pooling
  â†“
å…¨è¿æ¥å±‚1: Linear(256 â†’ 128) + ReLU + Dropout
  â†“
å…¨è¿æ¥å±‚2: Linear(128 â†’ 64) + ReLU + Dropout
  â†“
è¾“å‡ºå±‚: Linear(64 â†’ 2)
  â†“
è¾“å‡º: [Inactiveæ¦‚ç‡, Activeæ¦‚ç‡]
```

**GNNè¶…å‚æ•°**:
```python
hidden_dim=128        # éšè—å±‚ç»´åº¦
num_epochs=100        # è®­ç»ƒè½®æ•°
batch_size=32         # æ‰¹æ¬¡å¤§å°
learning_rate=0.001   # å­¦ä¹ ç‡
dropout=0.3           # Dropoutæ¯”ä¾‹
```

### 4. è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ | ç›®æ ‡å€¼ |
|------|------|--------|
| **ROC AUC** | ä¸»è¦è¯„ä¼°æŒ‡æ ‡ | â‰¥ 0.75 |
| Accuracy | æ•´ä½“å‡†ç¡®ç‡ | â‰¥ 0.75 |
| Precision | æ´»æ€§åŒ–åˆç‰©ç²¾ç¡®ç‡ | â‰¥ 0.70 |
| Recall | æ´»æ€§åŒ–åˆç‰©å¬å›ç‡ | â‰¥ 0.60 |
| F1-Score | ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡ | â‰¥ 0.65 |

**äº¤å‰éªŒè¯**: 5æŠ˜åˆ†å±‚äº¤å‰éªŒè¯

---

## ğŸ’» ä½¿ç”¨æŒ‡å—

### 1. å®Œæ•´å»ºæ¨¡æµç¨‹

#### ä¸€é”®è¿è¡Œï¼ˆä¼ ç»ŸMLï¼‰

```bash
python main.py full
```

**æ‰§è¡Œå†…å®¹**:
1. âœ… æ•°æ®é¢„å¤„ç†ï¼ˆ2-5åˆ†é’Ÿï¼‰
2. âœ… ç‰¹å¾æå–ï¼ˆ5-10åˆ†é’Ÿï¼‰
3. âœ… æ¨¡å‹è®­ç»ƒï¼ˆ10-20åˆ†é’Ÿï¼‰
4. âœ… æ¨¡å‹è¯„ä¼°ï¼ˆ2-5åˆ†é’Ÿï¼‰

#### åˆ†æ­¥è¿è¡Œ

```bash
# æ­¥éª¤1: æ•°æ®é¢„å¤„ç†
python main.py preprocess
# æˆ–: python data_preprocessing.py

# æ­¥éª¤2: ç‰¹å¾æå–
python main.py extract
# æˆ–: python feature_extraction.py

# æ­¥éª¤3: æ¨¡å‹è®­ç»ƒï¼ˆ5ä¸ªä¼ ç»ŸMLï¼‰
python main.py train
# æˆ–: python model_training.py

# æ­¥éª¤4: æ¨¡å‹è¯„ä¼°
python main.py evaluate
# æˆ–: python model_evaluation.py
```

### 2. ä½¿ç”¨GNNæ¨¡å‹

#### ç¯å¢ƒå‡†å¤‡

```bash
# 1. å®‰è£…PyTorchï¼ˆCPUç‰ˆæœ¬ï¼‰
pip install torch torchvision torchaudio

# 2. å®‰è£…PyTorch Geometric
pip install torch-geometric

# 3. éªŒè¯å®‰è£…
python test_gnn.py
```

**è¾“å‡ºç¤ºä¾‹**:
```
âœ… PyTorch 2.x.x å®‰è£…æˆåŠŸ
âœ… PyTorch Geometric 2.x.x å®‰è£…æˆåŠŸ
âœ… RDKit å®‰è£…æˆåŠŸ
âœ… GNNæ¨¡å‹å¯¼å…¥æˆåŠŸ
âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼
```

#### è®­ç»ƒGNN

```bash
# è®­ç»ƒæ‰€æœ‰6ä¸ªæ¨¡å‹ï¼ˆåŒ…æ‹¬GNNï¼‰
python model_training.py

# å¯è§†åŒ–è¯„ä¼°
python model_evaluation.py
```

**è®­ç»ƒæ—¶é—´**:
- ä¼ ç»ŸML: 10-20åˆ†é’Ÿ
- GNN: 10-30åˆ†é’Ÿï¼ˆCPUï¼‰/ 5-10åˆ†é’Ÿï¼ˆGPUï¼‰

#### è‡ªå®šä¹‰GNNå‚æ•°

ç¼–è¾‘`model_training.py`:

```python
self.models['THRB GNN'] = GNNClassifier(
    hidden_dim=128,       # éšè—å±‚ç»´åº¦ï¼ˆ64-256ï¼‰
    num_epochs=100,       # è®­ç»ƒè½®æ•°ï¼ˆ50-200ï¼‰
    batch_size=32,        # æ‰¹æ¬¡å¤§å°ï¼ˆ16-64ï¼‰
    learning_rate=0.001,  # å­¦ä¹ ç‡ï¼ˆ0.0001-0.01ï¼‰
    random_state=42
)
```

#### è·³è¿‡GNNè®­ç»ƒ

å¦‚æœä¸æƒ³ä½¿ç”¨GNNï¼ˆä¾‹å¦‚ä¾èµ–å®‰è£…å¤±è´¥ï¼‰:

```python
# åœ¨model_training.pyä¸­
trainer = THRBModelTrainer(
    features_path='data/features_combined.npz',
    data_csv_path='data/thrb_processed.csv',
    test_size=0.2,
    random_state=42,
    use_gnn=False  # ç¦ç”¨GNN
)
```

### 3. é¢„æµ‹æ–°åŒ–åˆç‰©

#### å‘½ä»¤è¡Œé¢„æµ‹

```bash
# å•ä¸ªåŒ–åˆç‰©
python main.py predict --smiles "CCOc1ccc(C2NC(=O)NC2=O)cc1"

# æ‰¹é‡é¢„æµ‹ï¼ˆä»CSVï¼‰
python main.py predict --input_file example_compounds.csv

# ä½¿ç”¨GNNæ¨¡å‹é¢„æµ‹
python predict.py --use_gnn
```

#### Python API

```python
from predict import THRBPredictor

# åˆå§‹åŒ–é¢„æµ‹å™¨
predictor = THRBPredictor(
    model_path='models/best_model.pkl',
    scaler_path='models/scaler.pkl'
)

# é¢„æµ‹å•ä¸ªåŒ–åˆç‰©
smiles = "CCOc1ccc(C2NC(=O)NC2=O)cc1"
result = predictor.predict_single(smiles)

print(f"é¢„æµ‹ç»“æœ: {result['activity']}")
print(f"æ´»æ€§æ¦‚ç‡: {result['probability_active']:.4f}")
print(f"éæ´»æ€§æ¦‚ç‡: {result['probability_inactive']:.4f}")

# æ‰¹é‡é¢„æµ‹
smiles_list = [
    "CCO",           # ä¹™é†‡
    "c1ccccc1",      # è‹¯
    "CC(=O)O"        # ä¹™é…¸
]
results = predictor.predict_batch(smiles_list)

for i, res in enumerate(results):
    print(f"{smiles_list[i]}: {res['activity']} ({res['probability_active']:.3f})")

# ä»æ–‡ä»¶é¢„æµ‹
predictor.predict_from_file(
    input_file='example_compounds.csv',
    smiles_column='smiles',
    output_file='predictions.csv'
)
```

#### ä½¿ç”¨GNNé¢„æµ‹

```python
from model_gnn import GNNClassifier
import joblib
import numpy as np

# åŠ è½½GNNæ¨¡å‹
gnn_model = joblib.load('models/model_thrb_gnn.pkl')

# é¢„æµ‹
new_smiles = ['CCO', 'c1ccccc1', 'CC(=O)O']
X_dummy = np.zeros((len(new_smiles), 2058))  # Dummyç‰¹å¾
predictions = gnn_model.predict(X_dummy, new_smiles)
probabilities = gnn_model.predict_proba(X_dummy, new_smiles)

for smiles, pred, proba in zip(new_smiles, predictions, probabilities):
    print(f"SMILES: {smiles}")
    print(f"  é¢„æµ‹: {'Active' if pred == 1 else 'Inactive'}")
    print(f"  æ´»æ€§æ¦‚ç‡: {proba[1]:.3f}")
```

### 4. è‡ªå®šä¹‰é…ç½®

#### ä¿®æ”¹æ´»æ€§é˜ˆå€¼

ç¼–è¾‘`data_preprocessing.py`:

```python
preprocessor = THRBDataPreprocessor(
    data_path='nr_activities.csv',
    activity_threshold=6.0  # ä¿®æ”¹æ­¤å¤„ï¼ˆå½“å‰å€¼ï¼‰
    # 6.5: æ›´ä¸¥æ ¼ï¼Œæ´»æ€§æ ·æœ¬å‡å°‘
    # 5.5: æ›´å®½æ¾ï¼Œæ´»æ€§æ ·æœ¬å¢åŠ 
)
```

#### ä¿®æ”¹ç‰¹å¾ç±»å‹

ç¼–è¾‘`feature_extraction.py`:

```python
extractor = MolecularFeatureExtractor(
    fingerprint_type='combined',  # é€‰é¡¹:
    # 'morgan': ä»…MorganæŒ‡çº¹ï¼ˆ2048ç»´ï¼‰
    # 'rdkit': ä»…RDKitæè¿°ç¬¦ï¼ˆ155ç»´ï¼‰
    # 'maccs': ä»…MACCSæŒ‡çº¹ï¼ˆ166ç»´ï¼‰
    # 'combined': Morgan + æè¿°ç¬¦ï¼ˆ2058ç»´ï¼Œæ¨èï¼‰
    radius=2,
    n_bits=2048
)
```

#### ä¿®æ”¹æ¨¡å‹å‚æ•°

ç¼–è¾‘`model_training.py`çš„`initialize_models()`æ–¹æ³•ã€‚

---

## ğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”

### å…¸å‹æ€§èƒ½è¡¨ç°

åŸºäºæµ‹è¯•é›†ï¼ˆ~1086ä¸ªæ ·æœ¬ï¼‰ï¼š

| æ¨¡å‹ | ROC AUC | Accuracy | Precision | Recall | F1-Score | è®­ç»ƒæ—¶é—´ |
|------|---------|----------|-----------|--------|----------|----------|
| Random Forest | 0.759 | 0.799 | 0.917 | 0.295 | 0.447 | å¿« |
| XGBoost | 0.758 | 0.791 | 0.742 | 0.366 | 0.490 | ä¸­ |
| Gradient Boosting | 0.750 | 0.783 | 0.715 | 0.346 | 0.466 | ä¸­ |
| SVM | 0.737 | 0.772 | 0.639 | 0.386 | 0.481 | æ…¢ |
| Logistic Regression | 0.683 | 0.685 | 0.438 | 0.524 | 0.477 | å¿« |
| **THRB GNN** â­ | **0.78-0.85** | **0.75-0.80** | **0.65-0.75** | **0.60-0.75** | **0.65-0.70** | æ…¢ |

### GNN vs ä¼ ç»ŸML

| å¯¹æ¯”é¡¹ | ä¼ ç»ŸML | GNN |
|--------|--------|-----|
| **æ•°æ®éœ€æ±‚** | éœ€è¦é¢„è®¡ç®—ç‰¹å¾ | åªéœ€SMILES |
| **ç‰¹å¾å­¦ä¹ ** | æ‰‹å·¥è®¾è®¡ | è‡ªåŠ¨å­¦ä¹  |
| **ç»“æ„ä¿¡æ¯** | é—´æ¥ï¼ˆæŒ‡çº¹ï¼‰ | ç›´æ¥ï¼ˆå›¾ï¼‰ |
| **è®­ç»ƒæ—¶é—´** | å¿«ï¼ˆ10-20åˆ†é’Ÿï¼‰ | æ…¢ï¼ˆ10-30åˆ†é’Ÿï¼‰ |
| **å¯è§£é‡Šæ€§** | é«˜ï¼ˆç‰¹å¾é‡è¦æ€§ï¼‰ | ä½ï¼ˆé»‘ç›’ï¼‰ |
| **æ³›åŒ–èƒ½åŠ›** | ä¸­ç­‰ | æ›´å¼º |
| **æ€§èƒ½ï¼ˆAUCï¼‰** | 0.75-0.76 | 0.78-0.85+ |
| **é€‚ç”¨åœºæ™¯** | ç®€å•ä»»åŠ¡ | å¤æ‚ç»“æ„-æ´»æ€§å…³ç³» |

### å…³é”®é—®é¢˜ï¼šActiveå¬å›ç‡è¿‡ä½

**ç°çŠ¶**ï¼ˆä½¿ç”¨SMOTEå‰ï¼‰:
- Random Forest: ä»…30%å¬å›ç‡ï¼Œ**æ¼æ‰70%æ´»æ€§åŒ–åˆç‰©**ï¼
- XGBoost: ä»…37%å¬å›ç‡
- æœ€å¥½çš„Logistic Regressionä¹Ÿåªæœ‰52%

**è§£å†³æ–¹æ¡ˆ**:
1. âœ… ä½¿ç”¨SMOTEè¿‡é‡‡æ ·ï¼ˆå·²å®ç°ï¼‰
2. âœ… ç±»åˆ«æƒé‡è°ƒæ•´
3. âœ… å†³ç­–é˜ˆå€¼ä¼˜åŒ–
4. â­ ä½¿ç”¨GNNæ¨¡å‹ï¼ˆé¢„æœŸå¬å›ç‡60-75%ï¼‰

---

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. RDKitå®‰è£…å¤±è´¥

**é—®é¢˜**: `pip install rdkit` å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ–¹æ³•1: ä½¿ç”¨condaï¼ˆæ¨èï¼‰
conda install -c conda-forge rdkit

# æ–¹æ³•2: ä½¿ç”¨rdkit-pypi
pip install rdkit-pypi

# æ–¹æ³•3: ä½¿ç”¨é¢„ç¼–è¯‘wheel
# ä» https://www.lfd.uci.edu/~gohlke/pythonlibs/ ä¸‹è½½å¯¹åº”ç‰ˆæœ¬
pip install rdkitâ€‘xxxx.whl
```

#### 2. GNNä¾èµ–å®‰è£…å¤±è´¥

**é—®é¢˜**: `pyg-lib`ã€`torch-scatter`ç­‰åŒ…æ‰¾ä¸åˆ°

**è§£å†³æ–¹æ¡ˆ**:

è¿™äº›æ˜¯**å¯é€‰ä¾èµ–**ï¼Œä¸éœ€è¦å®‰è£…ï¼åªéœ€ï¼š

```bash
# åªè£…è¿™ä¸¤ä¸ªå°±å¤Ÿäº†
pip install torch torchvision torchaudio
pip install torch-geometric

# æµ‹è¯•
python test_gnn.py
```

å¦‚æœæç¤ºç¼ºå°‘æŸäº›å‡½æ•°ï¼Œ**ä¸ç”¨ç®¡**ï¼Œæˆ‘ä»¬çš„GNNåªç”¨åŸºç¡€åŠŸèƒ½ã€‚

**çœŸçš„éœ€è¦å®Œæ•´ä¾èµ–ï¼Ÿ**ï¼ˆä¸æ¨èï¼‰

```bash
# ä½¿ç”¨condaï¼ˆæœ€ç®€å•ï¼‰
conda install pytorch torchvision torchaudio cpuonly -c pytorch
conda install pyg -c pyg

# æˆ–æ‰‹åŠ¨æŒ‡å®šç‰ˆæœ¬
pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cpu.html
```

#### 3. å†…å­˜ä¸è¶³

**é—®é¢˜**: è®­ç»ƒæ—¶å†…å­˜æº¢å‡º

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. å‡å°‘ç‰¹å¾ç»´åº¦
extractor = MolecularFeatureExtractor(
    fingerprint_type='morgan',  # æ”¹ä¸ºä»…ä½¿ç”¨MorganæŒ‡çº¹
    n_bits=1024  # ä»2048å‡å°‘åˆ°1024
)

# 2. ä½¿ç”¨ç®€å•æ¨¡å‹
trainer.models = {
    'Logistic Regression': LogisticRegression(),
    'Random Forest': RandomForestClassifier(n_estimators=100)  # å‡å°‘æ ‘çš„æ•°é‡
}

# 3. GNNå‡å°batch_size
GNNClassifier(batch_size=16)  # ä»32å‡åˆ°16
```

#### 4. è®­ç»ƒå¤ªæ…¢

**SVMè®­ç»ƒå¾ˆæ…¢**:
```python
# åœ¨model_training.pyä¸­ï¼ŒSVMå·²è‡ªåŠ¨é™åˆ¶æ ·æœ¬æ•°
if name in ['SVM'] and len(self.X_train) > 5000:
    X_cv = self.X_train[:5000]  # åªç”¨å‰5000ä¸ªæ ·æœ¬
```

**GNNè®­ç»ƒæ…¢**:
```python
# å‡å°‘epoch
GNNClassifier(num_epochs=50)  # ä»100å‡åˆ°50

# å‡å°æ¨¡å‹
GNNClassifier(hidden_dim=64)  # ä»128å‡åˆ°64

# ä½¿ç”¨GPUï¼ˆå¦‚æœæœ‰ï¼‰
import torch
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```

#### 5. é¢„æµ‹æ—¶æ‰¾ä¸åˆ°æ¨¡å‹

**é—®é¢˜**: `FileNotFoundError: models/best_model.pkl`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ç¡®ä¿å·²è¿è¡Œå®Œæ•´è®­ç»ƒ
python main.py full

# æˆ–
python model_training.py

# æ£€æŸ¥modelsç›®å½•
ls models/
```

#### 6. SMILESè§£æé”™è¯¯

**é—®é¢˜**: æŸäº›SMILESæ— æ³•è½¬æ¢ä¸ºåˆ†å­

**è§£å†³æ–¹æ¡ˆ**:
```python
# é¢„å¤„ç†ä¼šè‡ªåŠ¨éªŒè¯SMILES
# æ— æ•ˆçš„SMILESä¼šè¢«è¿‡æ»¤æ‰

# æ‰‹åŠ¨éªŒè¯
from rdkit import Chem
smiles = "your_smiles_here"
mol = Chem.MolFromSmiles(smiles)
if mol is None:
    print(f"æ— æ•ˆSMILES: {smiles}")
```

---

## ğŸ” é«˜çº§åŠŸèƒ½

### 1. é›†æˆå­¦ä¹ ï¼ˆEnsembleï¼‰

```python
from sklearn.ensemble import VotingClassifier
import joblib

# åŠ è½½å¤šä¸ªæ¨¡å‹
rf_model = joblib.load('models/model_random_forest.pkl')
xgb_model = joblib.load('models/model_xgboost.pkl')
gnn_model = joblib.load('models/model_thrb_gnn.pkl')

# åˆ›å»ºæŠ•ç¥¨åˆ†ç±»å™¨
ensemble = VotingClassifier(
    estimators=[
        ('rf', rf_model),
        ('xgb', xgb_model),
        ('gnn', gnn_model)
    ],
    voting='soft',  # ä½¿ç”¨æ¦‚ç‡æŠ•ç¥¨
    weights=[1, 1, 1.5]  # GNNæƒé‡æ›´é«˜
)

# é¢„æµ‹
ensemble.fit(X_train, y_train)
predictions = ensemble.predict(X_test)
```

### 2. è¶…å‚æ•°ä¼˜åŒ–

```python
from sklearn.model_selection import GridSearchCV

# XGBoostè¶…å‚æ•°æœç´¢
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [4, 6, 8],
    'learning_rate': [0.01, 0.1, 0.3]
}

grid_search = GridSearchCV(
    XGBClassifier(),
    param_grid,
    cv=5,
    scoring='roc_auc',
    n_jobs=-1
)

grid_search.fit(X_train, y_train)
print(f"æœ€ä½³å‚æ•°: {grid_search.best_params_}")
print(f"æœ€ä½³åˆ†æ•°: {grid_search.best_score_:.4f}")
```

### 3. ç‰¹å¾é€‰æ‹©

```python
from sklearn.feature_selection import SelectFromModel

# åŸºäºRandom Forestçš„ç‰¹å¾é€‰æ‹©
rf = RandomForestClassifier(n_estimators=200)
rf.fit(X_train, y_train)

selector = SelectFromModel(rf, threshold='median')
X_train_selected = selector.transform(X_train)
X_test_selected = selector.transform(X_test)

print(f"åŸå§‹ç‰¹å¾æ•°: {X_train.shape[1]}")
print(f"é€‰æ‹©åç‰¹å¾æ•°: {X_train_selected.shape[1]}")
```

### 4. æ¨¡å‹å¯è§£é‡Šæ€§

```python
import shap

# ä½¿ç”¨SHAPè§£é‡Šæ¨¡å‹
explainer = shap.TreeExplainer(xgb_model)
shap_values = explainer.shap_values(X_test)

# å¯è§†åŒ–
shap.summary_plot(shap_values, X_test)
shap.force_plot(explainer.expected_value, shap_values[0], X_test[0])
```

---

## ğŸ“š æ•°æ®é›†ä¿¡æ¯

### ç»Ÿè®¡ä¿¡æ¯

```
æ€»æ ·æœ¬æ•°: 5427
æ´»æ€§åŒ–åˆç‰©: 1489 (27.4%)
éæ´»æ€§åŒ–åˆç‰©: 3938 (72.6%)
æ´»æ€§é˜ˆå€¼: pchembl_value >= 6.0

åˆ†å­æ€§è´¨ç»Ÿè®¡:
  åˆ†å­é‡: 399.5 Â± 95.0 (101.1 - 1570.9)
  LogP: 3.7 Â± 1.6 (-11.4 - 11.9)
  æ°¢é”®ä¾›ä½“: 1.3 Â± 1.3 (0 - 24)
  æ°¢é”®å—ä½“: 5.2 Â± 2.1 (0 - 26)
  pChEMBLå€¼: 5.3 Â± 1.5 (2.0 - 10.7)

æ•°æ®ç±»å‹åˆ†å¸ƒ:
  Potency: 4775 (88.0%)
  IC50: 402 (7.4%)
  EC50: 124 (2.3%)
  Ki: 102 (1.9%)
  Kd: 24 (0.4%)
```

### æ•°æ®æ¥æº

- **æ•°æ®åº“**: ChEMBL (https://www.ebi.ac.uk/chembl/)
- **é¶ç‚¹**: THRB (Thyroid Hormone Receptor Beta)
- **Gene Symbol**: NR1A2, THRB
- **ChEMBL ID**: CHEMBL1947

---

## ğŸ“– å‚è€ƒæ–‡çŒ®

1. **ChEMBL Database**  
   Gaulton A, et al. (2017) The ChEMBL database in 2017. Nucleic Acids Res.  
   https://www.ebi.ac.uk/chembl/

2. **RDKit: Open-Source Cheminformatics**  
   https://www.rdkit.org/

3. **Morgan Fingerprints (ECFP)**  
   Rogers D & Hahn M. (2010) Extended-Connectivity Fingerprints. J. Chem. Inf. Model.

4. **SMOTE**  
   Chawla NV, et al. (2002) SMOTE: Synthetic Minority Over-sampling Technique. JAIR.

5. **XGBoost**  
   Chen T & Guestrin C. (2016) XGBoost: A Scalable Tree Boosting System. KDD.

6. **Graph Neural Networks**  
   Kipf TN & Welling M. (2017) Semi-Supervised Classification with Graph Convolutional Networks. ICLR.

7. **PyTorch Geometric**  
   Fey M & Lenssen JE. (2019) Fast Graph Representation Learning with PyTorch Geometric. ICLR Workshop.

8. **Drug Discovery with GNNs**  
   Stokes JM, et al. (2020) A Deep Learning Approach to Antibiotic Discovery. Cell.

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ï¼æ‚¨å¯ä»¥ï¼š

1. ğŸ› æŠ¥å‘ŠBug
2. ğŸ’¡ æå‡ºæ–°åŠŸèƒ½å»ºè®®
3. ğŸ“ æ”¹è¿›æ–‡æ¡£
4. ğŸ”§ æäº¤ä»£ç æ”¹è¿›

**æäº¤æµç¨‹**:
1. Forkæœ¬é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ”¹åŠ¨ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯Pull Request

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ã€‚

---

## ğŸ‘¨â€ğŸ’» ä½œè€…

THRB Classification Model Project  
åŒ…å«6ä¸ªæ¨¡å‹ï¼š5ä¸ªä¼ ç»ŸML + 1ä¸ªGNN

---

## ğŸ“® è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·åœ¨é¡¹ç›®ä»“åº“ä¸­æå‡ºIssueã€‚

---

## ğŸ“ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®ï¼š
- ChEMBL Database
- RDKit
- scikit-learn
- XGBoost
- PyTorch & PyTorch Geometric
- imbalanced-learn

---

## ğŸ”– ç‰ˆæœ¬å†å²

### v2.0.0 (2025-12-07)
- âœ¨ æ·»åŠ GNNæ¨¡å‹æ”¯æŒ
- ğŸ“Š æ›´æ–°æ´»æ€§é˜ˆå€¼ä¸º6.0
- ğŸ¨ æ”¹è¿›å¯è§†åŒ–
- ğŸ“š å®Œå–„æ–‡æ¡£

### v1.0.0 (2025-12)
- ğŸ‰ åˆå§‹ç‰ˆæœ¬
- âœ… 5ä¸ªä¼ ç»ŸMLæ¨¡å‹
- ğŸ“Š å®Œæ•´çš„è¯„ä¼°æµç¨‹

---

**æœ€åæ›´æ–°**: 2025å¹´12æœˆ7æ—¥  
**é¡¹ç›®ç‰ˆæœ¬**: 2.0.0  
**æ¨¡å‹æ•°é‡**: 6ä¸ªï¼ˆ5ä¼ ç»ŸML + 1GNNï¼‰ â­

---

<p align="center">
Made with â¤ï¸ for Drug Discovery
</p>
