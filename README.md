# THRB Binary Classification Model Project

This is a machine learning project for predicting compound activity against Thyroid Hormone Receptor Beta (THRB). Based on the ChEMBL database, the project uses **6 algorithms** (including traditional machine learning and Graph Neural Networks GNN) to build binary classification prediction models.

## Project Overview

### Core Features
- **Objective**: Predict activity of unknown compounds against THRB (active/inactive)
- **Dataset**: ~5400 THRB-related compound data (filtered from 81000+ records)
- **Models**: 6 algorithms (5 traditional ML + 1 GNN)
- **Performance**: ROC AUC 0.75-0.85+
- **Activity Definition**: pchembl_value â‰¥ **6.0** defines active compounds

## ğŸ“ Project Structure

```
THRB/
â”‚
â”œâ”€â”€ Core Scripts
â”‚   â”œâ”€â”€ main.py                     # Main entry point (traditional ML pipeline)
â”‚   â”œâ”€â”€ data_preprocessing.py       # Data preprocessing
â”‚   â”œâ”€â”€ feature_extraction.py       # Feature extraction
â”‚   â”œâ”€â”€ model_training.py           # Model training (6 models)
â”‚   â”œâ”€â”€ model_evaluation.py         # Model evaluation and visualization
â”‚   â”œâ”€â”€ model_gnn.py               # GNN model implementation â­
â”‚   â”œâ”€â”€ predict.py                  # Prediction module
â”‚   â””â”€â”€ test_gnn.py                # GNN environment testing â­
â”‚
â”œâ”€â”€ Data Files
â”‚   â”œâ”€â”€ nr_activities.csv           # Raw dataset (81000+ records)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ thrb_processed.csv      # Processed data (~5400 records)
â”‚   â”‚   â”œâ”€â”€ data_statistics.txt     # Data statistics
â”‚   â”‚   â”œâ”€â”€ features_combined.npz   # Combined features (2058 dims)
â”‚   â”‚   â””â”€â”€ features_morgan.npz     # Morgan fingerprints (2048 dims)
â”‚
â”œâ”€â”€ Model Files
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ best_model.pkl          # Best model
â”‚   â”‚   â”œâ”€â”€ scaler.pkl              # Feature scaler
â”‚   â”‚   â”œâ”€â”€ model_random_forest.pkl
â”‚   â”‚   â”œâ”€â”€ model_xgboost.pkl
â”‚   â”‚   â”œâ”€â”€ model_gradient_boosting.pkl
â”‚   â”‚   â”œâ”€â”€ model_svm.pkl
â”‚   â”‚   â”œâ”€â”€ model_logistic_regression.pkl
â”‚   â”‚   â”œâ”€â”€ model_thrb_gnn.pkl     # GNN model â­
â”‚   â”‚   â”œâ”€â”€ smiles_test.npy        # Test set SMILES â­
â”‚   â”‚   â”œâ”€â”€ model_comparison.csv    # Performance comparison
â”‚   â”‚   â””â”€â”€ evaluation_report.txt   # Detailed report
â”‚
â”œâ”€â”€ Results Files
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ roc_curves.png          # ROC curves (6 models)
â”‚       â”œâ”€â”€ precision_recall_curves.png
â”‚       â”œâ”€â”€ confusion_matrices.png  # Confusion matrices (6 models)
â”‚       â”œâ”€â”€ model_comparison.png
â”‚       â”œâ”€â”€ prediction_distributions.png
â”‚        classification_reports.txt
â”‚
â””â”€â”€ Documentation and Configuration
    â”œâ”€â”€ README.md                   # This document
    â””â”€â”€ requirements.txt            # Python dependencies
```


### Model Architecture

#### Traditional Machine Learning Models

**Random Forest**
```python
n_estimators=200
max_depth=20
min_samples_split=5
class_weight='balanced'  # Handle imbalance
```

**XGBoost**
```python
n_estimators=200
max_depth=6
learning_rate=0.1
subsample=0.8
scale_pos_weight=2.6  # Handle imbalance
```

**Class Imbalance Handling**:
- SMOTE oversampling
- Class weight adjustment
- From 3938:1489 â†’ Balanced dataset

**GNN Hyperparameters**:
```python
hidden_dim=128        # Hidden dimension
num_epochs=100        # Number of epochs
batch_size=32         # Batch size
learning_rate=0.001   # Learning rate
dropout=0.3           # Dropout ratio
```

### Complete Modeling Pipeline

```bash
python main.py full
```

#### Step-by-Step Execution

```bash
# Step 1: Data preprocessing
python main.py preprocess
# Or: python data_preprocessing.py

# Step 2: Feature extraction
python main.py extract
# Or: python feature_extraction.py

# Step 3: Model training
python main.py train
# Or: python model_training.py

# Step 4: Model evaluation
python main.py evaluate
# Or: python model_evaluation.py
```

#### Command Line Prediction

### 1. Predict single compound using best model
```bash
python predict.py --smiles "CCOc1ccc(C2NC(=O)NC2=O)cc1"
```
### 2. Predict using GNN model
```bash
python predict.py --model gnn --smiles "Cc1ccc(O)cc1"
```
### 3. Predict using XGBoost model
```bash
python predict.py --model xgboost --smiles "c1ccccc1"
```
### 4. Compare predictions from all models
```bash
python predict.py --compare --smiles "Cc1ccc(O)cc1"
```
### 5. Batch prediction from file (using GNN)
```bash
python predict.py --model gnn --input example_compounds.csv --output gnn_predictions.csv
```
### 6. Specify SMILES column name
```bash
python predict.py --input mydata.csv --smiles-column compound_smiles --output results.csv
```
## ğŸ“– References

1. **ChEMBL Database**  
   Gaulton A, et al. (2017) The ChEMBL database in 2017. Nucleic Acids Res.  
   https://www.ebi.ac.uk/chembl/

2. **RDKit: Open-Source Cheminformatics**  
   https://www.rdkit.org/

3. **Morgan Fingerprints (ECFP)**  
   Rogers D & Hahn M. (2010) Extended-Connectivity Fingerprints. J. Chem. Inf. Model.

4. **SMOTE**  
   Chawla NV, et al. (2002) SMOTE: Synthetic Minority Over-sampling Technique. JAIR.

5. **XGBoost**  
   Chen T & Guestrin C. (2016) XGBoost: A Scalable Tree Boosting System. KDD.

6. **Graph Neural Networks**  
   Kipf TN & Welling M. (2017) Semi-Supervised Classification with Graph Convolutional Networks. ICLR.

7. **PyTorch Geometric**  
   Fey M & Lenssen JE. (2019) Fast Graph Representation Learning with PyTorch Geometric. ICLR Workshop.

8. **Drug Discovery with GNNs**  
   Stokes JM, et al. (2020) A Deep Learning Approach to Antibiotic Discovery. Cell.
